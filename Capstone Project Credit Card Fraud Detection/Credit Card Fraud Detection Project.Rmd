---
title: "Credit Card Fraud Detection Project"
author: "Sho Nakamura"
date: "2023-07-21"
output: pdf_document
---

## Introduction

For this project, I decided to use a data set called "Credit Card Fraud Detection" from Kaggle and analyze the data. As the name of the dataset suggests, it does data analysis to detect credit card fraud. The reason why I chose this dataset is that there are many people who create more credit cards than necessary when they become working adults. As the number of credit cards increases, the probability of fraudulent use increases. Therefore, I wanted to know how much fraudulent use is detected. I also wanted to create a model that would detect fraudulent use with a high probability.

## Goal of Project

It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase. Therefore, a model with a high detection rate of fraudulent use is created. At least two different models or algorithms must be used, with at least one being more advanced than linear or logistic regression for prediction problems.

## Method

Describe the process of data explosion, data visualization and modeling.

## Import Library

```{r}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(caTools)) install.packages("caTools", repos = "http://cran.us.r-project.org")
if(!require(pROC)) install.packages("pROC", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(rpart.plot)) install.packages("rpart.plot", repos = "http://cran.us.r-project.org")
if(!require(gbm)) install.packages("gbm", repos = "http://cran.us.r-project.org")
if(!require(ranger)) install.packages("ranger", repos = "http://cran.us.r-project.org")
if(!require(Epi)) install.packages("Epi", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(ggplot2)
library(caret)
library(data.table)
library(dplyr)
library(corrplot)
library(caTools)
library(pROC)
library(rpart)
library(rpart.plot)
library(gbm, quietly=TRUE)
library(ranger)
library(Epi)

# Set seed
set.seed(1996)
```

## Load Dataset

```{r}
# Load dataset
credit_card <- read.csv("creditcard.csv")
```

## Data exploration and visualization

```{r}
# Check dataset
head(credit_card, 5)
```

```{r}
tail(credit_card, 5)
```

```{r}
names(credit_card)
```

```{r}
summary(credit_card)
```

```{r}
# Check fraud counts
table(credit_card$Class)
```

```{r}
# Check proportion of classes
prop.table(table(credit_card$Class))
```

The probability of credit fraud is fairly low.

```{r}
# Check the missing values
colSums(is.na(credit_card))
```

There are no missing values.

```{r}
var(credit_card$Amount)
sd(credit_card$Amount)
```

```{r}
# Plot distribution of class labels
credit_card %>%
  ggplot(aes(x = factor(Class), fill = factor(Class))) +
  geom_bar() +
  ggtitle("Distribution of Class Labels")
```

It turns out that fraudulent use of credit cards is rare.

```{r}
# Plot distribution of time of transaction by class
credit_card %>%
  ggplot(aes(x = Time, fill = factor(Class))) +
  geom_histogram(bins = 100) +
  ggtitle("Distribution of time of transaction by class") +
  labs(x = "Time (seconds)", y = "Number of Transactions") +
  facet_grid(Class ~ ., scales = 'free_y')
```

About two times, the time when the credit card was fraudulently used was concentrated. However, since it is unknown what happened from time, the element of time is unlikely to be used.

```{r}
# Plot correlation
corr <- cor(credit_card, use = "pairwise.complete.obs")
corrplot(corr, tl.col = "black")
```

Most of the elements seem unimportant.

## Build Model

```{r}
# Create dataset
credit_card$Amount <- scale(credit_card$Amount)
data <- credit_card[, -1]
head(data)
```

```{r}
# Split train and test data
split <- sample.split(data$Class, SplitRatio = 0.80)
train <- subset(data, split == TRUE)
test <- subset(data, split == FALSE)
dim(train)
dim(test)
```

### Logistic Regression Model

```{r}
## Logistic_Regression_Model ##
log_model <- glm(Class ~ ., train, family = "binomial")
log_pred <- predict(log_model, test, probability = TRUE)
roc(test$Class, log_pred, plot = TRUE, col = "red")
```

```{r}
print(roc(test$Class, log_pred, col = "red"))
```

### Decision Tree Model

```{r}
## Decision Tree ##
dt_model <- rpart(Class ~ ., train, method = "class")
dt_pred <- predict(dt_model, test, type = "class")
rpart.plot(dt_model)
```

```{r}
ROC(test$Class, dt_pred, plot = "ROC")
```

### Gradient Boosting Model (GBM)

```{r}
## Gradient Boosting (GBM) ##
system.time(
  gbm_model <- gbm(Class ~ .,
                   distribution = "bernoulli",
                   data = rbind(train, test),
                   n.trees = 500,
                   interaction.depth = 3,
                   n.minobsinnode = 100,
                   shrinkage = 0.01,
                   bag.fraction = 0.5,
                   train.fraction = nrow(train) / (nrow(train) + nrow(test))
 )
)
gbm.iter <- gbm.perf(gbm_model, method = "test")
model.influence = relative.influence(gbm_model, n.trees = gbm.iter, sort. = TRUE)
gbm_test <- predict(gbm_model, newdata = test, n.trees = gbm.iter)
gbm_auc <- roc(test$Class, gbm_test, plot = TRUE, col = "red")
```

```{r}
print(gbm_auc)
```

## Results

Analysis was performed with three models. How to show the result:

| Model                         | AUC   |
|-------------------------------|-------|
| Logistic Regression Model     | 0.970 |
| Decision Tree Model           | 0.944 |
| Gradient Boosting Model (GBM) | 0.967 |

## Conclusions

As you can see from the results, the Logistic Regression Model scored the highest. This was an unexpected result for me. I thought Decision Tree Model had the highest score, but it turned out to be the lowest score. That said, I think they are all good models.

In the future, I think it will be possible to exceed the score of the Logistic Regression Model by adjusting the parameters of the Gradient Boosting Model. Also, I think you can get a higher score by creating another model.
